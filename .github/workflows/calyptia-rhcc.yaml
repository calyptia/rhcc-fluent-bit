---
name: Deploy RHCC containers to staging

on:
  workflow_dispatch:
  push:

env:
  # Containers
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  calyptia-rhcc-deploy-staging-images:
    name: RHCC - Build multi-arch UBI 8 container images
    runs-on: ubuntu-latest
    environment: rhcc
    outputs:
      image: ${{ steps.meta.outputs.tags }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up QEMU
      uses: docker/setup-qemu-action@v1

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v1

    - name: Log in to the Container registry
      uses: docker/login-action@v1
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Build and run the tests
      continue-on-error: true
      uses: docker/build-push-action@v2
      with:
        file: ./calyptia/ubi8/Dockerfile
        context: ./calyptia/ubi8/
        platforms: linux/amd64
        push: false
        load: false
        target: test

    - name: Extract metadata from Github
      id: meta
      uses: docker/metadata-action@v3
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          raw,ubi8-${{ github.sha }}
          raw,ubi8

    - name: Build the production image
      uses: docker/build-push-action@v2
      with:
        file: ./calyptia/ubi8/Dockerfile
        context: ./calyptia/ubi8/
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        platforms: linux/amd64, linux/arm64
        push: true
        load: false
        target: production

  # Unfortunately no nested virtualisation support in Github actions for Linux
  # The only environment that does support it is MacOS but it is too old to install CRC
  # and CRC uses a guided installer there.
  # We also cannot use dev sandbox as we need to modify security constraints at a cluster level.
  # https://developers.redhat.com/developer-sandbox/get-started
  # The only option therefore is a cluster we have full control over.
  calyptia-rhcc-create-cluster:
    uses: calyptia/openshift-infra/.github/workflows/azure-redhat-cluster-create.yaml@main
    with:
      azure-location: ${{ inputs.azure-location }}
      cluster-resource-group: ${{ inputs.cluster-resource-group }}
      cluster-name: ${{ inputs.cluster-name }}
    secrets:
      azure-creds: ${{ secrets.AZURE_CREDENTIALS }}

  calyptia-rhcc-test-cluster:
    runs-on: ubuntu-latest
    needs: calyptia-rhcc-create-cluster
    env:
      NAMESPACE: test-logging
    steps:
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: OpenShift login
        uses: redhat-actions/oc-login@v1
        with:
          openshift_server_url: ${{ needs.calyptia-rhcc-create-cluster.outputs.server }}
          openshift_username: kubadmin
          openshift_password: ${{ needs.calyptia-rhcc-create-cluster.outputs.server }}
          insecure_skip_tls_verify: true
          namespace: ${{ env.NAMESPACE }}

      - name: Checkout Openshift examples repo
        uses: actions/checkout@v3
        with:
          repository: calyptia/openshift-fluent-bit-examples

      - name: Deploy Helm chart with our image
        run: |
          grafana-cloud/deploy-helm.sh --atomic --set image.repository=ghcr.io/calyptia/fluent-bit,image.tag=ubi8
        env:
          GRAFANA_CLOUD_PROM_USERNAME: ${{ secrets.GRAFANA_CLOUD_PROM_USERNAME }}
          GRAFANA_CLOUD_LOKI_USERNAME: ${{ secrets.GRAFANA_CLOUD_LOKI_USERNAME }}
          GRAFANA_CLOUD_APIKEY: ${{ secrets.GRAFANA_CLOUD_APIKEY }}
          GRAFANA_CLOUD_PROM_URL: prometheus-${{ secrets.GRAFANA_CLOUD_PROM_URL }}.grafana.net
          GRAFANA_CLOUD_LOKI_URL: logs-${{ secrets.GRAFANA_CLOUD_LOKI_URL }}.grafana.net
          LOKI_TENANT_ID: ${{ inputs.cluster-name }}
        shell: bash

      - name: Check logs and run for a while
        timeout-minutes: 2
        continue-on-error: true
        run: |
          kubectl logs --namespace $NAMESPACE \
            $(kubectl get pods --namespace $NAMESPACE \
              -l "app.kubernetes.io/name=fluent-bit,app.kubernetes.io/instance=fluent-bit" -o jsonpath="{.items[0].metadata.name}")
          sleep 60
          kubectl logs --namespace $NAMESPACE \
            $(kubectl get pods --namespace $NAMESPACE \
              -l "app.kubernetes.io/name=fluent-bit,app.kubernetes.io/instance=fluent-bit" -o jsonpath="{.items[0].metadata.name}") --since 60s

      - name: Error debug
        if: failure()
        run: |
          kubectl get namespace
          kubectl --namespace $NAMESPACE describe all
        shell: bash

      - name: Tear down
        if: always()
        continue-on-error: true
        run: |
          helm delete -n ${{ env.NAMESPACE }} fluent-bit
          oc delete all,secret -n ${{ env.NAMESPACE }}
        shell: bash
